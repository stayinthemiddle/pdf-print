#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
å¢å¼ºçš„ä¸­è‹±æ–‡æ–‡çŒ®é…å¯¹åˆ†æ
ä½¿ç”¨æ ‡é¢˜ç¿»è¯‘å’Œæ™ºèƒ½åŒ¹é…ç®—æ³•
"""

import re
import pandas as pd
from typing import Dict, Tuple, List
from deepseek_helper import DeepSeekClient
from paper_matcher import PaperMatcher
import logging

# ç¿»è¯‘Prompt
TRANSLATE_PROMPT = """è¯·å°†ä»¥ä¸‹ä¸­æ–‡å­¦æœ¯è®ºæ–‡æ ‡é¢˜ç¿»è¯‘æˆè‹±æ–‡ã€‚åªè¿”å›ç¿»è¯‘ç»“æœï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šã€‚

ä¸­æ–‡æ ‡é¢˜ï¼š{title}

è‹±æ–‡ç¿»è¯‘ï¼š"""

# å¢å¼ºçš„é…å¯¹åˆ†æPrompt
ENHANCED_MATCH_PROMPT = """ä½ æ˜¯ä¸€ä¸ªæ–‡çŒ®é…å¯¹ä¸“å®¶ã€‚è¯·åˆ†æä»¥ä¸‹ä¸¤ç¯‡è®ºæ–‡æ˜¯å¦ä¸ºåŒä¸€ç¯‡æ–‡çŒ®çš„ä¸­è‹±æ–‡ç‰ˆæœ¬ã€‚

æ³¨æ„ï¼šä¸­æ–‡ç‰ˆå¯èƒ½æ˜¯è‹±æ–‡ç‰ˆçš„ç¿»è¯‘ï¼Œå› æ­¤ï¼š
- å¹´ä»½åº”è¯¥ç›¸åŒï¼ˆä¸ªäººç¿»è¯‘ä¸ä¼šæ”¹å˜å‘è¡¨å¹´ä»½ï¼‰
- DOIå¯èƒ½ä¸åŒï¼ˆç¿»è¯‘ç‰ˆå¯èƒ½æ²¡æœ‰DOIæˆ–æœ‰ä¸åŒçš„DOIï¼‰
- ä½œè€…å§“åå¯èƒ½æœ‰ä¸åŒçš„è¡¨ç¤ºæ–¹å¼

æ–‡çŒ®1ï¼ˆä¸­æ–‡ï¼‰ï¼š
- æ ‡é¢˜ï¼š{title1}
- ä½œè€…ï¼š{authors1}
- å¹´ä»½ï¼š{year1}
- DOIï¼š{doi1}
- æ–‡æœ¬ç‰‡æ®µï¼š{text1}

æ–‡çŒ®2ï¼ˆè‹±æ–‡ï¼‰ï¼š
- æ ‡é¢˜ï¼š{title2}
- ä½œè€…ï¼š{authors2}
- å¹´ä»½ï¼š{year2}
- DOIï¼š{doi2}
- æ–‡æœ¬ç‰‡æ®µï¼š{text2}

è¯·ä»”ç»†åˆ†æå¹¶è¿”å›JSONæ ¼å¼çš„ç»“æœï¼š
{{
  "is_same_paper": trueæˆ–false,
  "confidence": 0-100çš„æ•°å€¼,
  "evidence": {{
    "title_match": "æ ‡é¢˜æ˜¯å¦åŒ¹é…ï¼ˆè€ƒè™‘ç¿»è¯‘ï¼‰",
    "author_match": "ä½œè€…æ˜¯å¦ä¸€è‡´",
    "content_match": "å†…å®¹æ˜¯å¦ç›¸ä¼¼",
    "year_explanation": "å¹´ä»½æ˜¯å¦ç›¸åŒæˆ–å·®å¼‚çš„åŸå› ",
    "doi_explanation": "DOIå·®å¼‚çš„è§£é‡Š"
  }},
  "conclusion": "åˆ¤æ–­ç†ç”±"
}}"""

class EnhancedMatcher:
    """å¢å¼ºçš„æ–‡çŒ®é…å¯¹å™¨"""
    
    def __init__(self):
        self.client = DeepSeekClient()
        self.logger = logging.getLogger(__name__)
        
    def translate_title(self, chinese_title: str) -> str:
        """å°†ä¸­æ–‡æ ‡é¢˜ç¿»è¯‘æˆè‹±æ–‡"""
        try:
            prompt = TRANSLATE_PROMPT.format(title=chinese_title)
            response = self.client.chat_completion(prompt)
            
            if response:
                translated = response['choices'][0]['message']['content'].strip()
                self.logger.info(f"ç¿»è¯‘ç»“æœ: {chinese_title} -> {translated}")
                return translated
            
        except Exception as e:
            self.logger.error(f"ç¿»è¯‘å¤±è´¥: {str(e)}")
        
        return ""
    
    def extract_author_names(self, authors_str: str) -> List[str]:
        """æå–ä½œè€…å§“åï¼ˆå¤„ç†ä¸åŒæ ¼å¼ï¼‰"""
        if not authors_str:
            return []
        
        # åˆ†å‰²ä½œè€…
        authors = re.split(r'[;,ï¼Œï¼›]', authors_str)
        
        # æ¸…ç†å’Œæ ‡å‡†åŒ–
        cleaned = []
        for author in authors:
            author = author.strip()
            if author:
                # ç§»é™¤æ•°å­—ä¸Šæ ‡ç­‰
                author = re.sub(r'\d+', '', author)
                # ç§»é™¤å¤šä½™ç©ºæ ¼
                author = ' '.join(author.split())
                if author:
                    cleaned.append(author)
        
        return cleaned
    
    def calculate_author_similarity(self, authors1: str, authors2: str) -> float:
        """è®¡ç®—ä½œè€…ç›¸ä¼¼åº¦"""
        list1 = self.extract_author_names(authors1)
        list2 = self.extract_author_names(authors2)
        
        if not list1 or not list2:
            return 0.0
        
        # æ£€æŸ¥ä¸»è¦ä½œè€…ï¼ˆç¬¬ä¸€ä½œè€…å’Œé€šè®¯ä½œè€…ï¼‰
        matches = 0
        
        # ç¬¬ä¸€ä½œè€…
        if list1 and list2:
            first1 = list1[0].lower()
            first2 = list2[0].lower()
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«ç›¸åŒçš„å§“æ°
            parts1 = first1.split()
            parts2 = first2.split()
            
            for p1 in parts1:
                for p2 in parts2:
                    if len(p1) > 2 and len(p2) > 2 and (p1 in p2 or p2 in p1):
                        matches += 1
                        break
        
        # è®¡ç®—æ•´ä½“åŒ¹é…ç‡
        total_authors = max(len(list1), len(list2))
        return min(1.0, matches / max(1, total_authors // 2))
    
    def enhanced_match(self, chinese_paper: pd.Series, english_paper: pd.Series, 
                      chinese_text: str = "", english_text: str = "") -> Dict:
        """ä½¿ç”¨å¢å¼ºç®—æ³•åŒ¹é…æ–‡çŒ®"""
        try:
            # ç¿»è¯‘ä¸­æ–‡æ ‡é¢˜
            translated_title = self.translate_title(chinese_paper['æ ‡é¢˜'])
            
            # å¿«é€Ÿç›¸ä¼¼åº¦æ£€æŸ¥
            quick_score = 0
            
            # æ ‡é¢˜ç›¸ä¼¼åº¦ï¼ˆè€ƒè™‘ç¿»è¯‘ï¼‰
            if translated_title and english_paper['æ ‡é¢˜']:
                # ç®€å•çš„å…³é”®è¯åŒ¹é…
                chinese_keywords = set(translated_title.lower().split())
                english_keywords = set(english_paper['æ ‡é¢˜'].lower().split())
                
                # å»é™¤å¸¸è§è¯
                stopwords = {'the', 'a', 'an', 'and', 'or', 'of', 'in', 'on', 'for', 'to', 'with'}
                chinese_keywords -= stopwords
                english_keywords -= stopwords
                
                if chinese_keywords and english_keywords:
                    overlap = len(chinese_keywords & english_keywords)
                    total = len(chinese_keywords | english_keywords)
                    title_sim = overlap / total if total > 0 else 0
                    quick_score += title_sim * 0.5
            
            # ä½œè€…ç›¸ä¼¼åº¦
            author_sim = self.calculate_author_similarity(
                chinese_paper.get('ä½œè€…', ''),
                english_paper.get('ä½œè€…', '')
            )
            quick_score += author_sim * 0.3
            
            # å¹´ä»½ç›¸ä¼¼åº¦ï¼ˆä¸ªäººç¿»è¯‘åº”è¯¥å¹´ä»½ç›¸åŒï¼‰
            try:
                year1 = int(chinese_paper.get('å¹´ä»½', 0))
                year2 = int(english_paper.get('å¹´ä»½', 0))
                if year1 and year2:
                    year_diff = abs(year1 - year2)
                    if year_diff == 0:
                        quick_score += 0.2  # å¹´ä»½ç›¸åŒï¼ŒåŠ åˆ†
                    elif year_diff <= 1:
                        quick_score += 0.05  # å…è®¸1å¹´å·®å¼‚ï¼ˆå¯èƒ½æ˜¯æå–é”™è¯¯ï¼‰
                    # å¤§äº1å¹´å·®å¼‚ä¸åŠ åˆ†
            except:
                pass
            
            # å¦‚æœå¿«é€Ÿå¾—åˆ†å¤ªä½ï¼Œè·³è¿‡è¯¦ç»†åˆ†æ
            if quick_score < 0.3:
                return {
                    'is_same_paper': False,
                    'confidence': int(quick_score * 100),
                    'evidence': {
                        'title_match': f"æ ‡é¢˜ç›¸ä¼¼åº¦ä½: {title_sim:.2f}" if 'title_sim' in locals() else "æ ‡é¢˜ä¸åŒ¹é…",
                        'author_match': f"ä½œè€…ç›¸ä¼¼åº¦: {author_sim:.2f}",
                    },
                    'conclusion': 'åŸºç¡€ç‰¹å¾ä¸åŒ¹é…'
                }
            
            # ä½¿ç”¨AIè¿›è¡Œæ·±åº¦åˆ†æ
            prompt = ENHANCED_MATCH_PROMPT.format(
                title1=chinese_paper['æ ‡é¢˜'],
                authors1=chinese_paper.get('ä½œè€…', 'æœªçŸ¥'),
                year1=chinese_paper.get('å¹´ä»½', 'æœªçŸ¥'),
                doi1=chinese_paper.get('DOI', 'æ— '),
                text1=chinese_text[:500] if chinese_text else 'æ— ',
                title2=english_paper['æ ‡é¢˜'],
                authors2=english_paper.get('ä½œè€…', 'æœªçŸ¥'),
                year2=english_paper.get('å¹´ä»½', 'æœªçŸ¥'),
                doi2=english_paper.get('DOI', 'æ— '),
                text2=english_text[:500] if english_text else 'æ— '
            )
            
            response = self.client.chat_completion(prompt)
            if response:
                result = self.client.extract_json_from_response(response)
                if result:
                    # æ·»åŠ ç¿»è¯‘ä¿¡æ¯
                    result['translated_title'] = translated_title
                    result['quick_score'] = quick_score
                    return result
            
            # å¦‚æœAIåˆ†æå¤±è´¥ï¼Œè¿”å›åŸºç¡€ç»“æœ
            return {
                'is_same_paper': quick_score > 0.5,
                'confidence': int(quick_score * 100),
                'evidence': {
                    'title_match': f"ç¿»è¯‘åæ ‡é¢˜: {translated_title}",
                    'author_match': f"ä½œè€…ç›¸ä¼¼åº¦: {author_sim:.2f}",
                    'quick_score': f"å¿«é€Ÿè¯„åˆ†: {quick_score:.2f}"
                },
                'conclusion': 'åŸºäºå¿«é€Ÿè¯„åˆ†åˆ¤æ–­'
            }
            
        except Exception as e:
            self.logger.error(f"å¢å¼ºåŒ¹é…å¤±è´¥: {str(e)}")
            return None


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    from llm_extractor import LLMExtractor
    
    parser = argparse.ArgumentParser(description='å¢å¼ºçš„æ–‡çŒ®é…å¯¹åˆ†æ')
    parser.add_argument('--update-excel', action='store_true', help='æ›´æ–°Excelæ–‡ä»¶')
    parser.add_argument('--show-details', action='store_true', help='æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯')
    
    args = parser.parse_args()
    
    # åˆå§‹åŒ–
    matcher = EnhancedMatcher()
    extractor = LLMExtractor()
    
    # åŠ è½½Excelæ•°æ®
    df = pd.read_excel('pdf_records.xlsx')
    chinese_papers = df[df['ç±»å‹'] == 'ä¸­æ–‡']
    english_papers = df[df['ç±»å‹'] == 'è‹±æ–‡']
    
    print("ğŸ” å¢å¼ºçš„æ–‡çŒ®é…å¯¹åˆ†æ")
    print("=" * 50)
    
    matches = []
    
    for _, c_paper in chinese_papers.iterrows():
        chinese_text = extractor.extract_text_from_pdf(f"ä¸­æ–‡pdf/{c_paper['æ–‡ä»¶å']}", max_pages=1)
        
        for _, e_paper in english_papers.iterrows():
            english_text = extractor.extract_text_from_pdf(f"è‹±æ–‡pdf/{e_paper['æ–‡ä»¶å']}", max_pages=1)
            
            print(f"\nåˆ†æ: {c_paper['æ–‡ä»¶å']} <-> {e_paper['æ–‡ä»¶å']}")
            
            result = matcher.enhanced_match(c_paper, e_paper, chinese_text, english_text)
            
            if result and result.get('is_same_paper'):
                matches.append({
                    'chinese_file': c_paper['æ–‡ä»¶å'],
                    'english_file': e_paper['æ–‡ä»¶å'],
                    'chinese_title': c_paper['æ ‡é¢˜'],
                    'english_title': e_paper['æ ‡é¢˜'],
                    'chinese_authors': c_paper.get('ä½œè€…', ''),
                    'english_authors': e_paper.get('ä½œè€…', ''),
                    'chinese_journal': c_paper.get('æœŸåˆŠ', ''),
                    'english_journal': e_paper.get('æœŸåˆŠ', ''),
                    'chinese_year': c_paper.get('å¹´ä»½', ''),
                    'english_year': e_paper.get('å¹´ä»½', ''),
                    'confidence': result.get('confidence', 0),
                    'evidence': result.get('evidence', {}),
                    'conclusion': result.get('conclusion', ''),
                    'translated_title': result.get('translated_title', '')
                })
                
                print(f"âœ… åŒ¹é…æˆåŠŸï¼ç½®ä¿¡åº¦: {result.get('confidence')}%")
                
                if args.show_details:
                    print(f"ç¿»è¯‘æ ‡é¢˜: {result.get('translated_title', '')}")
                    print(f"è¯æ®: {result.get('evidence', {})}")
            else:
                print(f"âŒ ä¸åŒ¹é…")
    
    print(f"\n\næ€»ç»“: æ‰¾åˆ° {len(matches)} ä¸ªé…å¯¹")
    
    # æ›´æ–°Excel
    if args.update_excel and matches:
        from paper_matcher import PaperMatcher
        pm = PaperMatcher()
        pm.update_excel_with_matches(matches)
        print("âœ… Excelå·²æ›´æ–°")
    
    # ç”ŸæˆæŠ¥å‘Š
    if matches:
        # ä½¿ç”¨å¢å¼ºçš„æŠ¥å‘Šæ¨¡æ¿
        from jinja2 import Template
        from datetime import datetime
        
        # è¯»å–æ¨¡æ¿
        with open('enhanced_report_template.html', 'r', encoding='utf-8') as f:
            template_str = f.read()
        
        # å‡†å¤‡æ•°æ®
        template_data = {
            'total_chinese': len(chinese_papers),
            'total_english': len(english_papers),
            'total_matches': len(matches),
            'high_confidence_matches': sum(1 for m in matches if m.get('confidence', 0) >= 80),
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'matches': matches
        }
        
        # æ¸²æŸ“æ¨¡æ¿
        template = Template(template_str)
        html_content = template.render(**template_data)
        
        # ä¿å­˜æŠ¥å‘Š
        with open("enhanced_matching_report.html", 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        print("ğŸ“Š æŠ¥å‘Šå·²ç”Ÿæˆ: enhanced_matching_report.html")


if __name__ == "__main__":
    main()